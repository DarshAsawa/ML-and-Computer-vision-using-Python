{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceClassifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name : darsh\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C://Users//dasaw//Documents//python//Facerecognition//darsh'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6b2220e37e73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphoto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_capture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mface_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphoto\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphoto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6b2220e37e73>\u001b[0m in \u001b[0;36mface_extractor\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaceClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfaces\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceClassifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "\n",
    "    # Initialize Webcam\n",
    "image_capture = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "#directory creation...\n",
    "parent_path = \"C://Users//dasaw//Documents//python//Facerecognition//\"\n",
    "name = input(\"Enter your name : \")\n",
    "path = os.path.join(parent_path,name)\n",
    "try:\n",
    "    os.mkdir(filepath)\n",
    "    print(\"Directory with your name created.\")\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    \n",
    "    \n",
    "while True:\n",
    "    status, photo = image_capture.read()\n",
    "    if face_extractor(photo) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(photo),(200,200))\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #store the photo at C:\\Users\\dasaw\\Documents\\mlops_ws\\faceRecog\n",
    "        filepath = filepath +\"//Darsh\" + str(count) +\".jpg\"\n",
    "        cv2.imwrite(filepath, face)\n",
    "        \n",
    "        #display picture with a custom text \n",
    "        cv2.putText(face,str(count),(10,10),cv2.FONT_HERSHEY_PLAIN,1,[255,0,0],2)\n",
    "        cv2.imshow(\"Face image\",face)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey()==13 or count==50:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "image_capture.release()\n",
    "print(\"Samples Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name : darsh\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C://Users//dasaw//Documents//python//Facerecognition//darsh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a9cb1380d87f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0monlyfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Create arrays for training data and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C://Users//dasaw//Documents//python//Facerecognition//darsh'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import os \n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "\n",
    "#filepath = \"C://Users//dasaw//Documents//python//\" \n",
    "parent_path = \"C://Users//dasaw//Documents//python//Facerecognition//\"\n",
    "name = input(\"Enter your name : \")\n",
    "filepath = os.path.join(parent_path,name)\n",
    "\n",
    "onlyfiles = [f for f in listdir(filepath) if isfile(join(filepath, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = filepath + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for labels and training data\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "#Creating model\n",
    "model=cv2.face_LBPHFaceRecognizer.create()\n",
    "model.train(Training_Data,Labels)\n",
    "\n",
    "print(\"Model Successfully Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model predicting and functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 55.18401082059214)\n",
      "(22, 57.81780218863011)\n",
      "(22, 59.956968274295356)\n",
      "(22, 60.56293910125975)\n",
      "(30, 61.07299168017758)\n",
      "(40, 55.71021694073309)\n",
      "(30, 55.373090743917544)\n",
      "(39, 57.77203587373194)\n",
      "(30, 57.76026719735682)\n",
      "(30, 57.211338087948)\n",
      "(30, 57.05165198333072)\n",
      "(41, 55.96159486793282)\n",
      "(41, 55.207949450424714)\n",
      "(41, 55.93276688940677)\n",
      "(28, 57.29465976392236)\n",
      "(48, 57.571356700079804)\n",
      "(41, 56.71264281868991)\n",
      "(41, 53.95298938958214)\n",
      "(41, 54.34431079497478)\n",
      "(2, 58.48685957438513)\n",
      "(48, 56.18986563529801)\n",
      "(38, 58.85292970247636)\n",
      "(30, 56.13969275497163)\n",
      "(2, 61.437546157888534)\n",
      "(30, 58.10478467015339)\n",
      "(30, 58.31611202625419)\n",
      "(39, 55.989317872513475)\n",
      "(41, 54.818127399477014)\n",
      "(41, 54.55519922226117)\n",
      "(39, 54.60933006760817)\n",
      "(30, 54.43427850908223)\n",
      "(35, 54.21557353539971)\n",
      "(41, 54.087890789344854)\n",
      "(41, 54.89470598339113)\n",
      "(41, 53.62074848313933)\n",
      "(41, 53.773464474255306)\n",
      "(41, 54.65001756512663)\n",
      "(35, 55.84901819052158)\n",
      "(30, 55.942154926541065)\n",
      "(30, 54.32283126017385)\n",
      "(39, 54.83989298035675)\n",
      "(30, 55.05627970069016)\n",
      "(40, 54.39046137871431)\n",
      "(41, 53.56487956635004)\n",
      "(30, 54.512582551178774)\n",
      "(39, 53.595672026544314)\n",
      "(41, 54.060875303975976)\n",
      "(41, 55.46491119512416)\n",
      "(30, 55.85845597140023)\n",
      "(30, 55.53131768770221)\n",
      "(30, 55.38481869523902)\n",
      "(41, 53.911651134466)\n",
      "(41, 53.542954500711)\n",
      "(30, 54.11698158420837)\n",
      "(48, 54.992433721416766)\n",
      "(41, 54.92116809083729)\n",
      "(30, 54.59309018371133)\n",
      "(39, 54.10782582702878)\n",
      "(39, 53.91959125199589)\n",
      "(39, 54.778702412128965)\n",
      "(30, 53.82258530764176)\n",
      "(41, 54.206393860696124)\n",
      "(30, 54.16673190666314)\n",
      "(41, 55.53105002740642)\n",
      "(41, 55.155726871291094)\n",
      "(30, 54.201843145667716)\n",
      "(41, 54.571657603493904)\n",
      "(39, 55.27880703370409)\n",
      "(41, 55.53013820428782)\n",
      "(41, 54.68702757001042)\n",
      "(41, 52.531513731138155)\n",
      "(41, 53.39242096362369)\n",
      "(41, 54.03388494182407)\n",
      "(40, 52.433332086562956)\n",
      "(41, 53.80638938269065)\n",
      "(29, 52.140031182348324)\n",
      "(48, 54.73460198221837)\n",
      "(48, 55.40153655844258)\n",
      "(48, 54.335192203580064)\n",
      "(41, 54.00179896631806)\n",
      "(7, 54.60500871067107)\n",
      "(29, 52.284410538632144)\n",
      "(41, 54.00355799638309)\n",
      "(2, 61.48466239824641)\n",
      "(2, 60.05563871687466)\n",
      "(38, 61.246033054846045)\n",
      "(35, 59.133761670318876)\n",
      "(38, 58.87986961774251)\n",
      "(2, 59.75645242553819)\n",
      "(28, 58.839066413693)\n",
      "(30, 58.490857884762754)\n",
      "(2, 58.21664517126804)\n",
      "(38, 58.729351028989726)\n",
      "(2, 56.754803734113075)\n",
      "(2, 57.91114262402335)\n",
      "(2, 60.71222008558649)\n",
      "(39, 58.02279681561029)\n",
      "(2, 58.88589662716568)\n",
      "(38, 61.18121143424418)\n",
      "(35, 58.662077498011904)\n",
      "(38, 61.02996467914641)\n",
      "(28, 59.65970186780043)\n",
      "(39, 58.145318315749925)\n",
      "(35, 55.50078786252718)\n",
      "(48, 55.10506749772849)\n",
      "(39, 55.740125633196044)\n",
      "(39, 54.177103069247586)\n",
      "(48, 56.53321452790708)\n",
      "(41, 56.5361487844453)\n",
      "(28, 57.34659770216128)\n",
      "(2, 57.53425063133476)\n",
      "(2, 58.36319286230627)\n",
      "(2, 57.73708501355645)\n",
      "(28, 57.95054389851592)\n",
      "(41, 57.36202311396054)\n",
      "(2, 59.41061699433755)\n",
      "(2, 59.62861745644261)\n",
      "(28, 58.86140483566284)\n",
      "(2, 60.698389814750655)\n",
      "(28, 58.80322484011928)\n",
      "(38, 60.9609024189001)\n",
      "(2, 60.397041321099884)\n",
      "(28, 57.592515355129294)\n",
      "(2, 58.01465454617949)\n",
      "(28, 57.94328259471861)\n",
      "(28, 56.98811154696763)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size = 0.5):\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray_image,1.3,5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped= img[y:y+h, x:x+w]\n",
    "        cropped = cv2.resize(cropped, (200, 200))\n",
    "    return img, cropped\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image, face = face_detector(frame)\n",
    "\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = model.predict(face)\n",
    "        print(results)\n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "\n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255,120,150), 2)\n",
    "\n",
    "        if confidence > 90:\n",
    "            #os.system(\"docker run  -d -i -t --name vimalos ubuntu:latest\")\n",
    "            cv2.putText(image, \"Hey Darsh\", (250, 450), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            #break\n",
    "            #webbrowser.open('http://google.com/')\n",
    "\n",
    "        else:\n",
    "            cv2.putText(image, \"Go away\", (250, 450), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
